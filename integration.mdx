---
title: 'Integration'
description: 'Integrate your API with your survey program of choice'
---

## Forsta

#### 1. Set up Javascript Tracker (optional)

Our [Javascript tracker](https://github.com/roundtableAI/alias-api/blob/main/tracking-script.js) generates a history of every change made for each open-ended textbox. To use this tracker, replace the value of the `textbox_id` variable at the top of the script with the HTML id of the relevant textbox and then store the generated `question_history`. You can also specify the max number of characters the parsed `question_history` should take before it stops tracking (by default, this is set to 25,000). Note that as is, the script only works if there is one textbox per page. *Also note that the script will need to be modified if participants can go "back" to edit their question.*

#### 2. Collect data and format

Run your survey, storing the `question_history` for each participant and each open-ended question they complete, and structure the data to make API calls as described below. Note that our API only takes data from open-ended questions.

#### 3. Call the API

Call the API using our endpoint at `https://roundtable.ai/api/alias/v011`. *Note: We recommend waiting at least 5 seconds between each API call as we work to scale.*

#### Example Usage

A more detailed script with examples for each value is shown in [call-api.py](https://github.com/roundtableAI/alias-api/blob/main/example/call-api.py).


```python
import requests

url = 'https://roundtable.ai/api/alias/v011'

# Data to be sent in the request body
data = {
    "questions": {...},  # Replace with your questions object
    "question_histories": {...},  # Replace with your change history object or leave empty
    "responses": {...},  # Replace with an object with the participant's final responses
    "survey_id": "survey123",
    "participant_id": "participant123"
}

# Headers to be sent in the request
headers = {
    "Content-Type": "application/json",
    "api_key": "your-api-key"  # Replace with your actual API key
}

# Make the POST request
response = requests.post(url, json=data, headers=headers)

# Parse the response
if response.status_code == 200:
    print("Success:", response.json())
else:
    # Get the body of the response and print
    response_body = response.json()
    print('Error: ', response_body)
```

## Qualtrics

The Qualtrics integration works by adding a new column to your datasets with response behavior for each participant. This data is then fed to the Alias API at the end of the survey (or whenever you choose to pass the survey data to the API).

#### 1. Set up Javascript Tracker

Our [Qualtrics javascript tracker](https://github.com/roundtableAI/alias-qualtrics-integration/blob/main/qualtrics-tracker.js) generates a history of every change made for each open-ended textbox. To use this tracker, simply paste the code into the "Javascript" block for any open-ended question (you must have at least one open-ended question to call the Alias API).

#### 2. Add an embedded data field

Add an embedded data field called `alias_data` to your survey.

#### 3. Run your survey

All of the data needed for the Alias API will be stored in the `alias_data` embedded data field.

#### 4. Export data and call the API

Export your survey data as a CSV from Qualtrics, and call the API using the [call-api.py](https://github.com/roundtableAI/alias-qualtrics-integration/blob/main/call-api.py) script. Note that you will have to add an ID for the survey, each participant, as well as your API key to this script. This script will call the API and automatically add new columns with data for (1) the total number of flags generated and (2) flags for each open-ended question (empty responses will be ignored).

## jsPsych

This repository contains details on using the [Roundtable Alias API](https://github.com/roundtableAI/alias-api) with JsPsych for survey bot and fraud detection.

#### 1. Setup

The [Alias tracker](https://github.com/roundtableAI/alias-tracker/blob/main/alias-tracker.js) integrates with JsPsych `survey-text` trials to identify potential fraudelent, inattentive, or bot-like responses to open-ended questions. You can use this as a naturalistic captcha to identify participants to exclude from your analyses.

The extension generates arrayss of all the change events to open-ended questions (called "question histories"), which you can then pass to our API. To use this extension, simply add a link to it in `index.html`, include it in the `initJsPsych` call, and then pass it as an extension to any `jsPsychSurveyText` questions you want to track (note that you must include at least one `survey-text` question with our extension).

The Alias tracker takes an optional initialization argument `max_n_characters`, when specifies the max number of characters the JSON string of each `question_history` can be (by default, this is 50,000; we highly recommend setting it to at least 20,000). The extension also requires a `page_id` parameter on every trial where the extension is used. This allows you to easily compare responses across participants even if there are conditional timelines or repeated questions.

We include a full example of using our extension in a JsPsych experiment in the [public/](https://github.com/roundtableAI/alias-tracker/blob/main/public) directory. Here is a simplified example:

```javascript
const jsPsych = initJsPsych({
  extensions: [
    { type: jsPsychAliasTracker, params: { max_n_characters:55000 } }
  ],
});

...

const openEndsTrial = {
  type: jsPsychSurveyText,
  questions: [
    { prompt: 'What do you think was the purpose of this experiment?', required: true, rows: 6 },
  ],
  extensions: [
    { type: jsPsychAliasTracker, params: { page_id:'page1' } }
  ]
}

...
```

#### 2. Calling the API

Our tracker automatically adds all of the data the Alias API needs to trial data with the `jsPsychAliasTracker` extension. This data is stored as `alias_questions`, `alias_responses`, and `alias_question_histories`. This data can be passed to our API without any further modifications. An example of parsing the data from our example experiment and passing it to the API is included in [call-api.py](https://github.com/roundtableAI/alias-tracker/blob/main/call-api.py).

#### 3. Running on Heroku

This repository provides code to deploy an Alias JsPsych experiment to Heroku, a cloud platform service. Follow the steps below to clone the repository, install necessary dependencies, and launch your experiment on Heroku.

```bash
git clone https://github.com/roundtableAI/alias-tracker.git  # Clones the repository
cd alias-tracker/                                            # Navigates into the directory
npm install                                                  # Installs all dependencies
heroku create your-app-name                                  # Creates a new Heroku app
git push heroku master                                       # Deploys the app to Heroku
heroku open                                                  # Opens the app in a web browser
```
